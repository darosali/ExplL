# ExplL

# Explainable Classifiers of Financial Transactions

## Overview  
Fraud detection is a critical challenge in financial transactions, with traditional rule-based methods often struggling to keep up with evolving fraud tactics. Machine learning (ML) has significantly improved fraud detection by identifying complex patterns in transaction data. However, a major limitation of ML models is their lack of interpretability, making it difficult for stakeholders to understand their decisions.  

This project explores the use of **SHAP (SHapley Additive exPlanations)** to provide interpretability for fraud detection models. We evaluate SHAP explanations for two classifiers: **XGBoost** and **Multilayer Perceptrons (MLP)**, using two financial transaction datasets. The study aims to enhance transparency, trust, and regulatory compliance in AI-powered fraud detection.  

## Key Features  
- **Application of SHAP** to explain fraud detection decisions.  
- **Comparison of XGBoost and MLP models** on financial transaction datasets.  
- **Evaluation of interpretability and practical implications** of explainable AI in finance.  

## Report  
For a detailed analysis, methodology, and results, please refer to the full report:  

ðŸ“„ [Read the full report](https://github.com/darosali/explainable-latent-classifiers)  

## Citation 

This project uses the following datasets:
- [**Amaretto: An Active Learning Framework for Money Laundering Detection**](https://doi.org/10.1109/ACCESS.2022.3167699)
  Labanca, Danilo and Primerano, Luca and Markland-Montgomery, Marcus and Polino, Mario and Carminati, Michele and Zanero, Stefano.  
  [Amaretto Dataset - A Synthetic Capital Market Dataset](https://github.com/necst/amaretto_dataset)
- [**Synthesizing Credit Card Transactions**](https://arxiv.org/abs/1910.03033)  
  Erik R. Altman
